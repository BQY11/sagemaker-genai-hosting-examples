{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7523a3e",
   "metadata": {},
   "source": [
    "# Import Libraries & Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49192c76",
   "metadata": {},
   "source": [
    "In this notebook, we will walk through various examples of using Bedrock and Bedrock Runtime APIs with Foundational Models hosted on Amazon SageMaker. We will discuss the following examples:\n",
    "\n",
    "1. [Converse API](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html)\n",
    "2. [Invoke Model API](https://docs.aws.amazon.com/bedrock/latest/userguide/inference-invoke.html)\n",
    "3. [Retrieve and Generate API](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent-runtime_RetrieveAndGenrate.html)\n",
    "4. [Retrieve API](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent-runtime_Retrieve.html)\n",
    "5. [Guard content with Amazon Bedrock Guardrails](https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d47654",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --force-reinstall -q -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20977278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7623b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361f3267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowledge_base import KnowledgeBasesForAmazonBedrock\n",
    "\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc63d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_client = boto3.client(\"iam\")\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sts_client = boto3.client('sts')\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "bedrock = boto3.client(\"bedrock\")\n",
    "bedrock_runtime = boto3.client(\"bedrock-runtime\")\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent\")\n",
    "bedrock_agent_runtime_client = boto3.client(\"bedrock-agent-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8464585",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94edd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"{region}, {account_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b8e159",
   "metadata": {},
   "source": [
    "## Setup - Create and Register Amazon SageMaker Endpoint with Amazon Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cb2696",
   "metadata": {},
   "source": [
    "### Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a66945",
   "metadata": {},
   "source": [
    "This notebook requires permissions to:\n",
    "\n",
    "- Create and delete Amazon IAM roles\n",
    "- Create, update and delete Amazon S3 buckets\n",
    "- Access Amazon Bedrock\n",
    "- Access to Amazon OpenSearch Serverless\n",
    "\n",
    "If running on SageMaker Studio, you should add the following managed policies to your role:\n",
    "\n",
    "- IAMFullAccess\n",
    "- AWSLambda_FullAccess\n",
    "- AmazonS3FullAccess\n",
    "- AmazonBedrockFullAccess\n",
    "- Custom policy for Amazon OpenSearch Serverless such as:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"aoss:*\",\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1db0ee",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Please make sure to enable Titan Text Embeddings V2 model access in Amazon Bedrock Console, as the notebook will use Titan Text Embeddings V2 models for generating embeddings. \n",
    "\n",
    "Follow instructions [here](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access-modify.html). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f73af",
   "metadata": {},
   "source": [
    "### Deploy a model via SageMaker JumpStart and registering it with Amazon Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cfb61e",
   "metadata": {},
   "source": [
    "#### Step 1\n",
    "\n",
    "Customers can log into the AWS Console, and navigate to the Amazon SageMaker service page via the search bar or the recently visited tab. On the SageMaker service page, select Studio from the navigation panel on the left. If you have not set up a SageMaker Domain to access Studio, please follow the steps outlined here. Once you have created a domain and a user, click on Open Studio. \n",
    "\n",
    "![step1](images/step1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdd7d6f",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "\n",
    "In SageMaker Studio, navigate to the JumpStart tab from the navigation panel on the left. Here, you will see a list of all the model providers that offer pre-trained foundation models. Certain model provider cards will have a “Bedrock Ready” tag, indicating that they offer models that can be registered with Bedrock after they are deployed to an endpoint via SageMaker Jumpstart. Click on a model provider card to learn more. \n",
    "\n",
    "![step2](images/step2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f34cd22",
   "metadata": {},
   "source": [
    "#### Step 3\n",
    "\n",
    "You can filter the list of models from the to view which models are supported by Bedrock. To filter, check the “Bedrock Ready” option under the Action tab. Search for Gemma 2 27B Instruct in the Search Models bar and click on the model card. \n",
    "\n",
    "![step3](images/step3.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192e8126",
   "metadata": {},
   "source": [
    "#### Step 4\n",
    "\n",
    "You can view the model details after clicking on the Model card. We will go ahead and deploy the model. Click on the Deploy button on the top right of the webpage. On the next page, Review the End User License Agreement and check the box. For the endpoint settings, leave them as the default values and click on Deploy. For additional details on the model deployment process with SageMaker Jumpstart, refer to this [link](https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-use-studio-updated-deploy.html). \n",
    "\n",
    "\n",
    "![step4](images/step4.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c29fec",
   "metadata": {},
   "source": [
    "#### Step 5\n",
    "\n",
    "Wait for a few minutes for the model to be successfully deployed to an Endpoint. Once the model is deployed, navigate to the Endpoint tab under Deployments from the navigation panel on the left. Click on the endpoint to see more details. \n",
    "\n",
    "\n",
    "![step5](images/step5.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b20259",
   "metadata": {},
   "source": [
    "#### Step 6\n",
    "\n",
    "In the details page for the endpoint, you will see a “Use with Bedrock Button”  at the top right of the webpage. Click on that button. \n",
    "\n",
    "![step6](images/step6.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d27023b",
   "metadata": {},
   "source": [
    "#### Step 7\n",
    "\n",
    "The “Use with Bedrock” button will redirect you to the Bedrock Service page in the console. It will direct you to register your existing endpoint in SageMaker. It will prefill the Endpoint ARN and Model ARN automatically. Review details and click on Register. \n",
    "\n",
    "![step7](images/step7.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308ff632",
   "metadata": {},
   "source": [
    "#### Step 8\n",
    "\n",
    "Once your SageMaker endpoint is registered with Bedrock, you can now invoke it via the Converse API! We can test our newly registered model in the Bedrock console. On the Bedrock service page, click on Models under Bedrock Marketplace in the navigation pane on the left. Click on Self-hosted deployments. \n",
    "\n",
    "![step8](images/step8.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dddf7b9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Make sure to put correct value for endpoint_arn. \n",
    "\n",
    "\n",
    "![endpointARN](images/EndpointARN.png)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3044a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_arn = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6103a7ce",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Gemma 2 27B Instruct supports the following common payload parameters. You may specify any subset of these parameters when invoking an endpoint.\n",
    "\n",
    "- do_sample: If True, activates logits sampling. If specified, it must be boolean.\n",
    "- max_new_tokens: Maximum number of generated tokens. If specified, it must be a positive integer.\n",
    "- repetition_penalty: A penalty for repetitive generated text. 1.0 means no penalty.\n",
    "- return_full_text: If True, input text will be part of the output generated text. If specified, it must be boolean. The default value for it is False.\n",
    "- seed: Random sampling seed.\n",
    "- temperature: Controls the randomness in the output. Higher temperature results in output sequence with low-probability words and lower temperature results in output sequence with high-probability words. If temperature -> 0, it results in greedy decoding. If specified, it must be a positive float.\n",
    "- top_k: In each step of text generation, sample from only the top_k most likely words. If specified, it must be a positive integer.\n",
    "- top_p: In each step of text generation, sample from the smallest possible set of words with cumulative probability top_p. If specified, it must be a float between 0 and 1.\n",
    "- details: Return generation details, to include output token logprobs and IDs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f3efe4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Gemma 2 27B Instruct does not support system prompts.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8d3923",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f0dffd",
   "metadata": {},
   "source": [
    "### Converse API (AWS CLI) with FMs hosted on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cccb0f8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Make sure to replace endpoint_arn with Amazon SageMaker Endpoint ARN. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72161cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws bedrock-runtime converse \\\n",
    "    --model-id endpoint_arn \\\n",
    "    --messages '[{\"role\": \"user\", \"content\": [{\"text\": \"What is Amazon doing in the field of generative AI?\"}]}]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0efcbfb",
   "metadata": {},
   "source": [
    "### Converse API (boto3) with FMs hosted on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f78dd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base inference parameters to use.\n",
    "inference_config = {\n",
    "        \"maxTokens\": 256,\n",
    "        \"temperature\": 0.1,\n",
    "        \"topP\": 0.999,\n",
    "}\n",
    "\n",
    "# Additional inference parameters to use.\n",
    "additional_model_fields = {\"top_k\": 250}\n",
    "\n",
    "\n",
    "response = bedrock_runtime.converse(\n",
    "    modelId=endpoint_arn,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": \"What is Amazon doing in the field of generative AI?\",\n",
    "                },\n",
    "            ]\n",
    "        },\n",
    "    ],\n",
    "    inferenceConfig=inference_config,\n",
    "    additionalModelRequestFields=additional_model_fields,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b553d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91619398",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"output\"][\"message\"][\"content\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5456184f",
   "metadata": {},
   "source": [
    "### Invoke Model API (boto3) with FMs hosted on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de014902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine base and additional parameters\n",
    "request_body = {\n",
    "    \"inputs\": \"What is Amazon doing in the field of generative AI?\",\n",
    "    \"parameters\": {\n",
    "        \"max_tokens\": 256,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.999,\n",
    "        \"top_k\": 250,\n",
    "        \"return_full_text\": True,\n",
    "        \"details\": True,\n",
    "        \"repetition_penalty\": 0.9\n",
    "    }\n",
    "}\n",
    "\n",
    "response = bedrock_runtime.invoke_model(\n",
    "    modelId=endpoint_arn,\n",
    "#     contentType='application/json',\n",
    "#     accept='application/json',\n",
    "    body=json.dumps(request_body)\n",
    ")\n",
    "\n",
    "# Parse the response\n",
    "response_body = json.loads(response['body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df582608",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d23fc81",
   "metadata": {},
   "source": [
    "## Retrieve data and generate AI responses  with Amazon Bedrock Knowledge Bases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a0d22b",
   "metadata": {},
   "source": [
    "We will now going to create a Knowledge Base for Amazon Bedrock and its requirements including:\n",
    "\n",
    "- [Amazon OpenSearch Serverless](https://aws.amazon.com/opensearch-service/features/serverless/) for the vector database\n",
    "- [AWS IAM](https://aws.amazon.com/iam/?gclid=Cj0KCQiA0fu5BhDQARIsAMXUBOIUK3yz8b91PiCpnXnXMCaQki8JThR5aWHqFMp0jXZmsJMr9vKDl9gaAoXJEALw_wcB&trk=da94b437-337f-4ee7-81b4-5dcf158370ab&sc_channel=ps&ef_id=Cj0KCQiA0fu5BhDQARIsAMXUBOIUK3yz8b91PiCpnXnXMCaQki8JThR5aWHqFMp0jXZmsJMr9vKDl9gaAoXJEALw_wcB:G:s&s_kwcid=AL!4422!3!651737511581!e!!g!!amazon%20iam!19845796027!146736269229) roles and permissions\n",
    "- [Amazon S3](https://aws.amazon.com/s3/) bucket to store the knowledge base documents\n",
    "\n",
    "To create the knowledge base and its dependencies, we will use the BedrockKnowledgeBase support class, available in this folder. It allows you to create a new knowledge base, ingest documents to the knowledge base data source and delete the resources after you are done working with this lab.\n",
    "\n",
    "Note that creation of the Amazon OpenSearch Serverless collection can take several minutes. You can use the Amazon OpenSearch Serverless console to monitor creation progress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10476c1e",
   "metadata": {},
   "source": [
    "![data-ingestion](images/data_ingestion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202ca991",
   "metadata": {},
   "source": [
    "For more details on how to setup Amazon Bedrock Knowledge Base checkout the following resources:\n",
    "\n",
    "1. [Workshop](https://github.com/aws-samples/amazon-bedrock-workshop/tree/main/02_KnowledgeBases_and_RAG)\n",
    "   \n",
    "2. [User Guide](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908cba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = f\"{region}-{account_id}\"\n",
    "knowledge_base_name = f'sample-kb'\n",
    "knowledge_base_description = \"Knowledge Base containing Amazon's Letters to Shareholders\"\n",
    "bucket_name = f'{knowledge_base_name}-{suffix}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b83fd",
   "metadata": {},
   "source": [
    "Steps:\n",
    "- Create Amazon Bedrock Knowledge Base execution role with necessary policies for accessing data from S3 and writing embeddings into OSS.\n",
    "- Create an empty OpenSearch serverless index.\n",
    "- Download documents\n",
    "- Create Amazon Bedrock knowledge base\n",
    "- Create a data source within knowledge base which will connect to Amazon S3\n",
    "- Start an ingestion job using KB APIs which will read data from s3, chunk it, convert chunks into embeddings using - Amazon Titan Embeddings model and then store these embeddings in AOSS. All of this without having to build, deploy and manage the data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d902e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = KnowledgeBasesForAmazonBedrock()\n",
    "kb_id, ds_id = kb.create_or_retrieve_knowledge_base(knowledge_base_name, knowledge_base_description, bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf6489a",
   "metadata": {},
   "source": [
    "In the example RAG workflow we will upload the da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c8fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and prepare dataset\n",
    "!mkdir -p ./kb_documents\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "urls = [\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/2022-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/2021-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2021/ar/Amazon-2020-Shareholder-Letter-and-1997-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2020/ar/2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "filenames = [\n",
    "    'AMZN-2022-Shareholder-Letter.pdf',\n",
    "    'AMZN-2021-Shareholder-Letter.pdf',\n",
    "    'AMZN-2020-Shareholder-Letter.pdf',\n",
    "    'AMZN-2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "data_root = \"./kb_documents/\"\n",
    "\n",
    "for idx, url in enumerate(urls):\n",
    "    file_path = data_root + filenames[idx]\n",
    "    urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcbe97d",
   "metadata": {},
   "source": [
    "We now upload the knowledge base documents to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f823b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_directory(path, bucket_name):\n",
    "        for root,dirs,files in os.walk(path):\n",
    "            for file in files:\n",
    "                file_to_upload = os.path.join(root,file)\n",
    "                print(f\"uploading file {file_to_upload} to {bucket_name}\")\n",
    "                s3_client.upload_file(file_to_upload,bucket_name,file)\n",
    "\n",
    "upload_directory(\"kb_documents\", bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b79eca",
   "metadata": {},
   "source": [
    "And ingest the documents to the knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e5926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that the kb is available\n",
    "i_status = ['CREATING', 'DELETING', 'UPDATING']\n",
    "while bedrock_agent_client.get_knowledge_base(knowledgeBaseId=kb_id)['knowledgeBase']['status'] in i_status:\n",
    "    time.sleep(10)\n",
    "\n",
    "# sync knowledge base\n",
    "kb.synchronize_data(kb_id, ds_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f97e1a0",
   "metadata": {},
   "source": [
    "### Retrieve and Generate API with FMs hosted on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f08ada3",
   "metadata": {},
   "source": [
    "RetreiveAndGenerate API provided by Amazon Bedrock Knowledge Bases converts user queries into embeddings, searches the knowledge base, get the relevant results, augment the prompt and then invokes a LLM to generate the response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e3d083",
   "metadata": {},
   "source": [
    "![ragAPI](images/retrieveAndGenerate.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d15bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_template = \"\"\"\n",
    "You are a question answering agent. I will provide you with a set of search results. The user will provide you with a question. Your job is to answer the user's question using only information from the search results. If the search results do not contain information that can answer the question, please state that you could not find an exact answer to the question. \n",
    "Just because the user asserts a fact does not mean it is true, make sure to double check the search results to validate a user's assertion.\n",
    "\n",
    "Here are the search results in numbered order:\n",
    "$search_results$\n",
    "\n",
    "$output_format_instructions$\n",
    "\n",
    "Here is the user's query:\n",
    "$query$\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc133d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestration_template = \"\"\"\n",
    "You are a query creation agent. You will be provided with a function and a description of what it searches over. The user will provide you a question, and your job is to determine the optimal query to use based on the user's question. \n",
    "Here are a few examples of queries formed by other search function selection and query creation agents: \n",
    "\n",
    "<examples>\n",
    "  <example>\n",
    "    <question> What if my vehicle is totaled in an accident? </question>\n",
    "    <generated_query> what happens if my vehicle is totaled </generated_query>\n",
    "  </example>\n",
    "  <example>\n",
    "    <question> I am relocating within the same state. Can I keep my current agent? </question>\n",
    "    <generated_query> can I keep my current agent when moving in state </generated_query>\n",
    "  </example>\n",
    "</examples> \n",
    "  \n",
    "You should also pay attention to the conversation history between the user and the search engine in order to gain the context necessary to create the query. \n",
    "Here's another example that shows how you should reference the conversation history when generating a query:\n",
    "\n",
    "<example>\n",
    "  <example_conversation_history>\n",
    "    <example_conversation>\n",
    "      <question> How many vehicles can I include in a quote in Kansas </question>\n",
    "      <answer> You can include 5 vehicles in a quote if you live in Kansas </answer>\n",
    "    </example_conversation>\n",
    "    <example_conversation>\n",
    "      <question> What about texas? </question>\n",
    "      <answer> You can include 3 vehicles in a quote if you live in Texas </answer>\n",
    "    </example_conversation>\n",
    "  </example_conversation_history>\n",
    "</example> \n",
    "\n",
    "IMPORTANT: the elements in the <example> tags should not be assumed to have been provided to you to use UNLESS they are also explicitly given to you below. \n",
    "All of the values and information within the examples (the questions, answers, and function calls) are strictly part of the examples and have not been provided to you. \n",
    "\n",
    "Here is the current conversation history: \n",
    "$conversation_history$\n",
    "\n",
    "$output_format_instructions$\n",
    "\n",
    "Here is the user's query:\n",
    "$query$\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f714e0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "    input={\n",
    "        \"text\": \"What is Amazon doing in the field of generative AI?\"\n",
    "    },\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            \"generationConfiguration\": {\n",
    "                \"inferenceConfig\": {\n",
    "                    \"textInferenceConfig\": {\n",
    "                        \"maxTokens\": 512,\n",
    "                        \"temperature\": 0.1,\n",
    "                        \"topP\": 0.9\n",
    "                    }\n",
    "                },\n",
    "                \"promptTemplate\": {\n",
    "                    \"textPromptTemplate\": generation_template\n",
    "                }\n",
    "            },\n",
    "            \"knowledgeBaseId\": kb_id,\n",
    "            \"orchestrationConfiguration\": {\n",
    "                \"inferenceConfig\": {\n",
    "                    \"textInferenceConfig\": {\n",
    "                        \"maxTokens\": 512,\n",
    "                        \"temperature\": 0.1,\n",
    "                        \"topP\": 0.9\n",
    "                    }\n",
    "                },\n",
    "                \"promptTemplate\": {\n",
    "                    \"textPromptTemplate\": orchestration_template\n",
    "                },\n",
    "            },\n",
    "            \"modelArn\": endpoint_arn,\n",
    "            \"retrievalConfiguration\": {\n",
    "                \"vectorSearchConfiguration\": {\n",
    "                    \"numberOfResults\":5\n",
    "                } \n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response['output']['text'],end='\\n'*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9453bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b2820",
   "metadata": {},
   "source": [
    "## Stop harmful content in models using Amazon Bedrock Guardrails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e204107",
   "metadata": {},
   "source": [
    "Guardrails for Amazon Bedrock have multiple components which include Content Filters, Denied Topics, Word and Phrase Filters, and Sensitive Word (PII & Regex) Filters. For a full list check out the [documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-create.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec64c158",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_response = bedrock.create_guardrail(\n",
    "    name='fiduciary-advice',\n",
    "    description='Prevents the our model from providing fiduciary advice.',\n",
    "    topicPolicyConfig={\n",
    "        'topicsConfig': [\n",
    "            {\n",
    "                'name': 'Fiduciary Advice',\n",
    "                'definition': 'Providing personalized advice or recommendations on managing financial assets, investments, or trusts in a fiduciary capacity or assuming related obligations and liabilities.',\n",
    "                'examples': [\n",
    "                    'What stocks should I invest in for my retirement?',\n",
    "                    'Is it a good idea to put my money in a mutual fund?',\n",
    "                    'How should I allocate my 401(k) investments?',\n",
    "                    'What type of trust fund should I set up for my children?',\n",
    "                    'Should I hire a financial advisor to manage my investments?'\n",
    "                ],\n",
    "                'type': 'DENY'\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    contentPolicyConfig={\n",
    "        'filtersConfig': [\n",
    "            {\n",
    "                'type': 'SEXUAL',\n",
    "                'inputStrength': 'HIGH',\n",
    "                'outputStrength': 'HIGH'\n",
    "            },\n",
    "            {\n",
    "                'type': 'VIOLENCE',\n",
    "                'inputStrength': 'HIGH',\n",
    "                'outputStrength': 'HIGH'\n",
    "            },\n",
    "            {\n",
    "                'type': 'HATE',\n",
    "                'inputStrength': 'HIGH',\n",
    "                'outputStrength': 'HIGH'\n",
    "            },\n",
    "            {\n",
    "                'type': 'INSULTS',\n",
    "                'inputStrength': 'HIGH',\n",
    "                'outputStrength': 'HIGH'\n",
    "            },\n",
    "            {\n",
    "                'type': 'MISCONDUCT',\n",
    "                'inputStrength': 'HIGH',\n",
    "                'outputStrength': 'HIGH'\n",
    "            },\n",
    "            {\n",
    "                'type': 'PROMPT_ATTACK',\n",
    "                'inputStrength': 'HIGH',\n",
    "                'outputStrength': 'NONE'\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    wordPolicyConfig={\n",
    "        'wordsConfig': [\n",
    "            {'text': 'fiduciary advice'},\n",
    "            {'text': 'investment recommendations'},\n",
    "            {'text': 'stock picks'},\n",
    "            {'text': 'financial planning guidance'},\n",
    "            {'text': 'portfolio allocation advice'},\n",
    "            {'text': 'retirement fund suggestions'},\n",
    "            {'text': 'wealth management tips'},\n",
    "            {'text': 'trust fund setup'},\n",
    "            {'text': 'investment strategy'},\n",
    "            {'text': 'financial advisor recommendations'}\n",
    "        ],\n",
    "        'managedWordListsConfig': [\n",
    "            {'type': 'PROFANITY'}\n",
    "        ]\n",
    "    },\n",
    "    sensitiveInformationPolicyConfig={\n",
    "        'piiEntitiesConfig': [\n",
    "            {'type': 'EMAIL', 'action': 'ANONYMIZE'},\n",
    "            {'type': 'PHONE', 'action': 'ANONYMIZE'},\n",
    "            {'type': 'NAME', 'action': 'ANONYMIZE'},\n",
    "            {'type': 'US_SOCIAL_SECURITY_NUMBER', 'action': 'BLOCK'},\n",
    "            {'type': 'US_BANK_ACCOUNT_NUMBER', 'action': 'BLOCK'},\n",
    "            {'type': 'CREDIT_DEBIT_CARD_NUMBER', 'action': 'BLOCK'}\n",
    "        ],\n",
    "        'regexesConfig': [\n",
    "            {\n",
    "                'name': 'Account Number',\n",
    "                'description': 'Matches account numbers in the format XXXXXX1234',\n",
    "                'pattern': r'\\b\\d{6}\\d{4}\\b',\n",
    "                'action': 'ANONYMIZE'\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    contextualGroundingPolicyConfig={\n",
    "        'filtersConfig': [\n",
    "            {\n",
    "                'type': 'GROUNDING',\n",
    "                'threshold': 0.5\n",
    "            },\n",
    "            {\n",
    "                'type': 'RELEVANCE',\n",
    "                'threshold': 0.5\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    blockedInputMessaging=\"\"\"I can provide general info about Amazon's recent advances.\"\"\",\n",
    "    blockedOutputsMessaging=\"\"\"I can provide general info about Amazon's recent advances. \"\"\",\n",
    "    tags=[\n",
    "        {'key': 'purpose', 'value': 'fiduciary-advice-prevention'},\n",
    "        {'key': 'environment', 'value': 'production'}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(create_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf39f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's create a version for our Guardrail \n",
    "version_response = bedrock.create_guardrail_version(\n",
    "    guardrailIdentifier=create_response['guardrailId'],\n",
    "    description='Version of Guardrail'\n",
    ")\n",
    "print(version_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a61af",
   "metadata": {},
   "outputs": [],
   "source": [
    "guardrail_identifier = create_response[\"guardrailId\"]\n",
    "guardrail_version = version_response[\"version\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b0c00c",
   "metadata": {},
   "source": [
    "### Step 1: Retrieve relevant chunks from Amazon Bedrock Knowledge Base using Retrieve API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef83dd2",
   "metadata": {},
   "source": [
    "![retrieve](images/retrieveAPI.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39848516",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_documents = bedrock_agent_runtime_client.retrieve(\n",
    "    retrievalQuery= {\n",
    "        \"text\": \"What is Amazon doing in the field of generative AI?\"\n",
    "    },\n",
    "    knowledgeBaseId=kb_id,\n",
    "    retrievalConfiguration= {\n",
    "        \"vectorSearchConfiguration\": {\n",
    "            \"numberOfResults\": 1\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87fdd0e",
   "metadata": {},
   "source": [
    "### Step 2 Invoke model with Coverse API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3832cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_model(prompt, source, inference_config=None, additional_model_field=None):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"guardContent\": {\n",
    "                        \"text\": {\n",
    "                            \"text\": source,\n",
    "                            \"qualifiers\": [\"grounding_source\"],\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"guardContent\": {\n",
    "                        \"text\": {\n",
    "                            \"text\": prompt,\n",
    "                            \"qualifiers\": [\"query\"],\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "    if not inference_config:\n",
    "        # Base inference parameters to use.\n",
    "        inference_config = {\n",
    "                \"maxTokens\": 256,\n",
    "                \"temperature\": 0.1,\n",
    "                \"topP\": 0.999,\n",
    "        }\n",
    "    \n",
    "    if not additional_model_field:\n",
    "        # Additional inference parameters to use.\n",
    "        additional_model_fields = {\"top_k\": 250}\n",
    "\n",
    "\n",
    "    response = bedrock_runtime.converse(\n",
    "        modelId=endpoint_arn,\n",
    "        messages=messages,\n",
    "        inferenceConfig=inference_config,\n",
    "        additionalModelRequestFields=additional_model_fields,\n",
    "        guardrailConfig={\n",
    "            'guardrailIdentifier': guardrail_identifier,\n",
    "            'guardrailVersion': guardrail_version\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    return response[\"output\"][\"message\"][\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7720a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_model(prompt=\"What is Amazon doing in the field of generative AI?\", source=relevant_documents[\"retrievalResults\"][0][\"content\"][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da2dc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_model(prompt=\"Should I buy bitcoin?\", source=relevant_documents[\"retrievalResults\"][0][\"content\"][\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
