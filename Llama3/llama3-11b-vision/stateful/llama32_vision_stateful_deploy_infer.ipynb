{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35429457",
   "metadata": {},
   "source": [
    "# LLava stateful inference with SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc57174",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "This notebook uses SageMaker notebook instance `conda_pytorch_p310` kernel, demonstrates how to use TorchServe to deploy Llama 3.2 vision Model on SageMaker. \n",
    "\n",
    "This is the code accompanying the workshop <TODO>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f165f5",
   "metadata": {},
   "source": [
    "## Step 0: Let's bump up SageMaker and import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d397660f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.14\n",
      "aws-cli/1.34.16 Python/3.10.14 Linux/5.10.224-212.876.amzn2.x86_64 botocore/1.35.35\n"
     ]
    }
   ],
   "source": [
    "!python --version && aws --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a2f2b9fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-model-archiver in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.12.0)\n",
      "Requirement already satisfied: enum-compat in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch-model-archiver) (0.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -Uq pip\n",
    "!pip install -Uq sagemaker\n",
    "!pip install torch-model-archiver\n",
    "!pip install -Uq botocore\n",
    "!pip install -Uq boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "fab0afe0-7d63-465d-bb53-2758f09ed3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.0.1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(override=True)  # Loads the variables from .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "856bbaae-40e7-491b-aa51-be55be51d5cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"TS_HF_TOKEN_VALUE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "87c4f583-1349-4322-afed-9cbfeb476db4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import importlib\n",
    "import botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "58626ec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a3f1ec20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "account=043632497353, region=us-west-2, role=arn:aws:iam::043632497353:role/sm-vision-stateful-role-SageMakerEndpointRole-OiHgNy330sKT, output_path=s3://sagemaker-us-west-2-043632497353/torchserve\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model, image_uris, serializers, deserializers\n",
    "barebone_session = sagemaker.session.Session()  # barebone sagemaker session to get current region\n",
    "# region name of the current SageMaker Studio environment\n",
    "region = barebone_session._region_name\n",
    "boto3_session=boto3.session.Session(region_name=region)\n",
    "# Create a SageMaker runtime client object using your IAM role ARN\n",
    "smr = boto3.client('sagemaker-runtime', region_name=region)\n",
    "# Create a SageMaker client object\n",
    "sm = boto3.client('sagemaker', region_name=region)\n",
    "# execution role for the endpoint\n",
    "role = sagemaker.get_execution_role()  \n",
    "# sagemaker session for interacting with different AWS APIs\n",
    "sess= sagemaker.session.Session(boto3_session, sagemaker_client=sm, sagemaker_runtime_client=smr)  \n",
    "# account_id of the current SageMaker Studio environment\n",
    "account = sess.account_id()  \n",
    "\n",
    "# Configuration:\n",
    "bucket_name = sess.default_bucket()\n",
    "prefix = \"torchserve\"\n",
    "output_path = f\"s3://{bucket_name}/{prefix}\"\n",
    "model_name = \"llama32vision-sm\"\n",
    "print(f'account={account}, region={region}, role={role}, output_path={output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f1db99",
   "metadata": {},
   "source": [
    "## Step 1: Build a BYOD TorchServe Docker container and push it to Amazon ECR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e6d968",
   "metadata": {},
   "source": [
    "1. Create an ECR repo: https://docs.aws.amazon.com/AmazonECR/latest/userguide/repository-create.html\n",
    "2. Get Base Image: https://github.com/aws/deep-learning-containers/blob/master/available_images.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3cbaa005-d32b-41af-bf90-6ddabbdc2579",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use the output from the print below to run ./build_and_push.sh in a termianl. You get better feedback in terminal.\n",
      "cd docker && ./build_and_push.sh llama32-11b-vision-stateful 1.0 763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-inference:2.3.0-gpu-py311-cu121-ubuntu20.04-sagemaker us-west-2 043632497353\n",
      "if you do endup running this command in a terminal , you can skip the next cell\n"
     ]
    }
   ],
   "source": [
    "baseimage = f\"763104351884.dkr.ecr.{region}.amazonaws.com/pytorch-inference:2.3.0-gpu-py311-cu121-ubuntu20.04-sagemaker\"\n",
    "reponame = \"llama32-11b-vision-stateful\"\n",
    "versiontag = \"1.0\"\n",
    "print(\"use the output from the print below to run ./build_and_push.sh in a termianl. You get better feedback in terminal.\")\n",
    "print (f\"cd docker && ./build_and_push.sh {reponame} {versiontag} {baseimage} {region} {account}\")\n",
    "print(\"if you do endup running this command in a terminal , you can skip the next cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6e412ff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%capture build_output\n",
    "\n",
    "# # Build our own docker image\n",
    "# !cd docker && ./build_and_push.sh {reponame} {versiontag} {baseimage} {region} {account}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "15351a14-0a4f-4e69-a737-4801042e6735",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-inference:2.3.0-gpu-py311-cu121-ubuntu20.04-sagemaker\n"
     ]
    }
   ],
   "source": [
    "# Update container\n",
    "container = f\"{account}.dkr.ecr.{region}.amazonaws.com/{reponame}:{versiontag}\"\n",
    "container\n",
    "print(baseimage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dc696a",
   "metadata": {},
   "source": [
    "## Step2: Build TorchServe Model Artifacts and Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "eebe9031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rm -rf code/{model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3e0438c7-a038-4e6d-bf9c-801ab3c511a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd code && torch-model-archiver --model-name {model_name} --version 1.0 --handler handler/custom_handler.py --config-file handler/model-config.yaml --archive-format no-archive --extra-files handler/ -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b84b41e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: llama32vision-sm/data_types.py to s3://sagemaker-us-west-2-043632497353/torchserve/llama32vision-sm/data_types.py\n",
      "upload: llama32vision-sm/__init__.py to s3://sagemaker-us-west-2-043632497353/torchserve/llama32vision-sm/__init__.py\n",
      "upload: llama32vision-sm/custom_handler.py to s3://sagemaker-us-west-2-043632497353/torchserve/llama32vision-sm/custom_handler.py\n",
      "upload: llama32vision-sm/inference_api.py to s3://sagemaker-us-west-2-043632497353/torchserve/llama32vision-sm/inference_api.py\n",
      "upload: llama32vision-sm/MAR-INF/MANIFEST.json to s3://sagemaker-us-west-2-043632497353/torchserve/llama32vision-sm/MAR-INF/MANIFEST.json\n",
      "upload: llama32vision-sm/utils.py to s3://sagemaker-us-west-2-043632497353/torchserve/llama32vision-sm/utils.py\n",
      "upload: llama32vision-sm/model-config.yaml to s3://sagemaker-us-west-2-043632497353/torchserve/llama32vision-sm/model-config.yaml\n"
     ]
    }
   ],
   "source": [
    "!cd code && aws s3 cp {model_name} {output_path}/{model_name} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "223542c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-043632497353/torchserve/llama32vision-sm/\n"
     ]
    }
   ],
   "source": [
    "s3_uri = f\"{output_path}/{model_name}/\"\n",
    "print(s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a07123",
   "metadata": {},
   "source": [
    "## Step3: Create SageMaker Endpont"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d13c4",
   "metadata": {},
   "source": [
    "### 3.1 Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "eefa91ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sagemaker.model.Model object at 0x7f585803f550>\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "instance_type = \"ml.p4d.24xlarge\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(model_name)\n",
    "\n",
    "model = Model(\n",
    "    name=model_name + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"),\n",
    "    # Enable SageMaker uncompressed model artifacts via \"S3DataType\": \"S3Prefix\"\n",
    "    model_data={\n",
    "        \"S3DataSource\": {\n",
    "                \"S3Uri\": s3_uri,\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"CompressionType\": \"None\",\n",
    "        }\n",
    "    },\n",
    "    image_uri=container,\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    env={\n",
    "        # TorchServe configuration file\n",
    "        \"TS_CONFIG_FILE\": \"/home/model-server/config.properties\",\n",
    "        # Disable token authorization for REST APIs\n",
    "        \"TS_DISABLE_TOKEN_AUTHORIZATION\": \"true\", \n",
    "        # Headers to indicate Session ID\n",
    "        \"TS_HEADER_KEY_SEQUENCE_ID\": \"X-Amzn-SageMaker-Session-Id\",\n",
    "        \"TS_REQUEST_SEQUENCE_ID\": \"X-Amzn-SageMaker-Session-Id\",\n",
    "        # Headers to indicate closed session\n",
    "        \"TS_HEADER_KEY_SEQUENCE_END\": \"X-Amzn-SageMaker-Closed-Session-Id\",\n",
    "        \"TS_REQUEST_SEQUENCE_END\": \"X-Amzn-SageMaker-Closed-Session-Id\",\n",
    "        # Enable system metrics aggregation\n",
    "        \"TS_DISABLE_SYSTEM_METRICS\": \"false\",\n",
    "        \"TS_HF_TOKEN\": os.environ[\"TS_HF_TOKEN_VALUE\"]\n",
    "    },\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2c3f57",
   "metadata": {},
   "source": [
    "### 3.2 Deploy Model and Create Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "99966473",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    }
   ],
   "source": [
    "model.deploy(\n",
    "    initial_instance_count=1, # increase the number of instances based on your load\n",
    "    instance_type=instance_type,\n",
    "    endpoint_name=endpoint_name,\n",
    "    #volume_size=512, # increase the size to store large model\n",
    "    model_data_download_timeout=3600, \n",
    "    container_startup_health_check_timeout=3600, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b043907",
   "metadata": {},
   "source": [
    "### 3.3 Create a Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e8073073",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor: {'endpoint_name': 'llama32vision-sm-2024-10-07-22-04-35-140', 'sagemaker_session': <sagemaker.session.Session object at 0x7f585803e200>, 'serializer': <sagemaker.base_serializers.IdentitySerializer object at 0x7f590e9a5630>, 'deserializer': <sagemaker.base_deserializers.BytesDeserializer object at 0x7f590e9a5cf0>}\n"
     ]
    }
   ],
   "source": [
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=model.endpoint_name,\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "print(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "aec7b26d-fa4a-4225-a547-9402ce27e51f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predictor = sagemaker.predictor.Predictor(\n",
    "#     endpoint_name='llava-sm-2024-09-04-06-35-10-354',\n",
    "#     sagemaker_session=sess\n",
    "# )\n",
    "# print(predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e1d5c6",
   "metadata": {},
   "source": [
    "## Step4: Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4d96ce7f-c63d-4e22-b0b4-c67b507c34eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Add necessary modules path to sys.path\n",
    "import os, sys\n",
    "\n",
    "demo_data_path = os.path.join(os.getcwd(), \"code/handler\")\n",
    "if demo_data_path not in sys.path:\n",
    "    sys.path.append(demo_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "688ede86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.4.1)\n",
      "Requirement already satisfied: dataclasses_json in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.6.7)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (1.13.0)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.77)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dataclasses_json) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dataclasses_json) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses_json) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses_json) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses_json) (3.1.2)\n"
     ]
    }
   ],
   "source": [
    "#Install dependencies\n",
    "!pip install torch dataclasses_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b229206",
   "metadata": {},
   "source": [
    "### 4.1 Open Session 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3f65e073-07b3-4dbe-8f5f-c2d9107dbb18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_url=\"https://images.pexels.com/photos/1519753/pexels-photo-1519753.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9e77cd2a-a20f-420d-9910-a65ed0f7edee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_url=\"https://images.pexels.com/photos/1519753/pexels-photo-1519753.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9c388f61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSessionResponse(session_id='ts-seq-387e7c95-e46c-43d2-9bca-d1d4d3ac071a')\n",
      "CPU times: user 14.2 ms, sys: 7.74 ms, total: 21.9 ms\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from data_types import (\n",
    "    BaseRequest,\n",
    "    CloseSessionRequest,\n",
    "    StartSessionRequest,\n",
    "    TextPromptRequest,\n",
    "    OpenSessionResponse,\n",
    "    TextPromptResponse,\n",
    "    CloseSessionResponse\n",
    ")\n",
    "\n",
    "ts_request_sequence_id = \"SessionId\"\n",
    "\n",
    "\n",
    "def send_and_check_request(r, seq_id):\n",
    "    response = smr.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=r.to_json(),\n",
    "        ContentType=\"application/json\",\n",
    "        SessionId=seq_id\n",
    "    )\n",
    "    assert response[\"ResponseMetadata\"][\"HTTPStatusCode\"] == 200, f\"Sending request failed: {r}\"\n",
    "    return response['Body'].readlines()[0]\n",
    "\n",
    "open_request = StartSessionRequest(\n",
    "    type=\"start_session\",\n",
    "    path=image_url,\n",
    ")\n",
    "\n",
    "open_response = send_and_check_request(open_request, \"NEW_SESSION\")\n",
    "open_response = OpenSessionResponse.from_json(open_response)\n",
    "print(open_response)\n",
    "assert open_response.session_id.startswith(\"ts-seq-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b5f86c2e-d1ef-4b14-9fc9-4eaf5ba74b4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ts-seq-387e7c95-e46c-43d2-9bca-d1d4d3ac071a'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_response.session_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6466cb",
   "metadata": {},
   "source": [
    "### 4.2 Send Text Promt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "410d996a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end_header_id|>\n",
      "\n",
      "This aerial image presents a stunning bird's-eye view of a tropical island, showcasing a lush forest, a small house, and a vibrant turquoise sea.\n",
      "\n",
      "The island's forest is characterized by a diverse array of green trees, with a few palm trees scattered throughout. A small, white house with a gray roof is nestled among the trees, accompanied by a smaller, red-roofed structure to its left. The shoreline is marked by a rocky area, where the sea meets the land, and the water's edge is dotted with large rocks and boulders.\n",
      "\n",
      "The sea itself is a brilliant turquoise hue, with a subtle gradient of lighter shades towards the center. The overall atmosphere of the image exudes a sense of serenity and tranquility, evoking a peaceful and idyllic setting.<|eot_id|>\n",
      "CPU times: user 4.95 ms, sys: 185 μs, total: 5.13 ms\n",
      "Wall time: 7.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_prompt_request1 = TextPromptRequest(\n",
    "    type=\"send_text_prompt\",\n",
    "    session_id=open_response.session_id,\n",
    "    prompt_text=\"describe the picture\"\n",
    ")\n",
    "\n",
    "text_prompt_response1 = send_and_check_request(text_prompt_request1, open_response.session_id)\n",
    "text_prompt_response1 = TextPromptResponse.from_json(text_prompt_response1)\n",
    "print(text_prompt_response1.response_text)\n",
    "assert text_prompt_response1.response_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfacc14b",
   "metadata": {},
   "source": [
    "### 4.3 Send Text Promt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "502be89c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end_header_id|>\n",
      "\n",
      "There is no mountain in the picture. The image shows a tropical island with a rocky shoreline and a dense forest of palm trees and other vegetation. The water is a bright blue color, indicating that it is likely a tropical or subtropical region. The overall atmosphere of the image suggests a warm and sunny day, with the sun shining down on the island and the water.<|eot_id|>\n",
      "CPU times: user 4.92 ms, sys: 0 ns, total: 4.92 ms\n",
      "Wall time: 3.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_prompt_request2 = TextPromptRequest(\n",
    "    type=\"send_text_prompt\",\n",
    "    session_id=open_response.session_id,\n",
    "    prompt_text=\"is there a mountain in the picture, describe it\"\n",
    ")\n",
    "\n",
    "text_prompt_response2 = send_and_check_request(text_prompt_request2, open_response.session_id)\n",
    "text_prompt_response2 = TextPromptResponse.from_json(text_prompt_response2)\n",
    "print(text_prompt_response2.response_text)\n",
    "assert text_prompt_response2.response_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfb7b2b",
   "metadata": {},
   "source": [
    "### 4.4 Close session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7dcf9239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# close session\n",
    "close_request = CloseSessionRequest(\n",
    "    type=\"close_session\",\n",
    "    session_id=open_response.session_id,\n",
    ")\n",
    "    \n",
    "close_response = send_and_check_request(\n",
    "    close_request, open_response.session_id\n",
    ")\n",
    "\n",
    "close_response = CloseSessionResponse.from_json(close_response)\n",
    "assert close_response.success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "87a3f455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess.delete_endpoint(endpoint_name)\n",
    "sess.delete_endpoint_config(endpoint_name)\n",
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0388105-8b40-4d7a-a74b-a544bd7b79ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
